논문 제목 : "Sequencer: Deep LSTM for Image Classification"
  - 귀납적 편향(Inductive Bias)이란?
    - 모델이 학습 과정에서 가정하거나 선호하는 특정 패턴이나 구조
    - 사과 바나나 예시
  - LSTM 기반 Sequencer 모델 제안, 귀납적 편향에 대한 새로운 관점
  

# 소개
  - 과거는 vision 분야에서 탁월한 성과를 지닌 CNN, 현재는 self-attention을 활용한 ViT
  - 다른 분야의 아키텍쳐는 비전 분야에서 어떤 효과를 보일지 관심
  * 제안하는 모델 Sequencer은 BiLSTM를 이용, macro-architecture 디자인은 ViTs를 따름
  - ImageNet-1K 데이터로 사전학습, 고해상도 이미지에 강점

# 방법론
  ## LSTM
  - LSTM은 입력게이트, 출력게이트, 망각게이트로 구조
  - BiLSTM은 상호 의존성이 예상되는 시퀀스에 장점을 갖고 있다.

  ## 모델 아키텍쳐
    - self-attention을 LSTM으로 대체
    * 입력 - 패치 임베딩 - 시퀀서 블록 - 패치 병합 - 시퀀서 블록 - PW linear? - 시퀀서 블록 - PW linear - 시퀀서 블록 - 레이어 norm - GA 풀링 - Linear - 클래스
      - 시퀀서 블록은 BiLSTM층과 MLP로 구성
      * BiLSTM2D 레이어 구조는 식 (5), (6), (7)과 같다.
      → 고해상도 이미지에 메모리 경제성과 처리 효율이 좋다. (처리해야할 데이터도 적고 시간복잡도도 적다.)

# 실험
  ## IN-1K
    - 기존 모델들 보다 좋은 정확도
  ## IN-1K Fine tuning
    - 224² 해상도에서 사전 훈련된 Sequencer2D-L 모델을 392² 해상도의 IN-1K 데이터셋에서 미세 조정하여 향상된 성능
  ## 아블레이션 연구
    - Sequencer 아키텍처의 구성 요소들의 중요성과 효과를 입증
  ## 전이학습과 의미론적 분할
    - 전이 학습 및 의미론적 분할 실험을 통해 우수한 일반화 성능과 전이성

느낀점 : 시계열에서 잘 다룬다고 들었던 LSTM을 vision 분야에 접목시키는 점이 인상깊었고 특히, 고해상도 이미지에 대한 효율을 보여주는 것이 신기했습니다.
실험 결과도 제가 생각했을때는 성과가 충분히 있었는데 어떤 상황에도 이 성과가 일반화가 될지 궁금했습니다.
