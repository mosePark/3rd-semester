Attention and Transformer

% 강의자료와 위키독스의 딥러닝을 이용한 자연어 처리 입문 참고

# RNN 요약
  구조 : ℎ𝑡 =𝜎(𝑊*𝑥_𝑡 +𝑈*ℎ_{𝑡−1}+𝑏)
  이전 은닉층의 정보를 다음 은닉층에서 활용, U도 역전파를 거쳐 갱신해야함

# RNN의 유형
- One-to-Many
  하나의 입력을 받아 여러 개의 출력을 예측
  예를 들어, 이미지 캡셔닝에서는 하나의 이미지를 주고 그 이미지를 설명하는 여러 단어(즉, 문장)를 생성
  
- Many-to-One
  여러 입력을 받아 하나의 출력을 예측
  예를 들어, 감정 분석에서는 여러 단어(즉, 문장)를 입력으로 받아 하나의 감정을 예측
  
- Many-to-Many
  여러 입력을 받아 여러 출력을 예측
  예를 들어, 기계 번역에서는 한 언어의 여러 단어(즉, 문장)를 입력으로 받아 다른 언어의 여러 단어(즉, 문장)로 번역
  시퀀스-투-시퀀스(Seq2Seq) 모델은 전체 시퀀스 입력 후 출력을 생성하는 형태로, 예를 들어 문장 생성에서는 입력 단어를 주고 다음 단어를 예측

# Seq2Seq

  Seq2Seq 모델은 인코더와 디코더로 구성됩니다.
  인코더: 입력 시퀀스를 고정 크기의 컨텍스트 벡터로 압축합니다.
  디코더: 이전 출력을 바탕으로 새로운 출력 시퀀스를 생성합니다.
  티처 포싱: 디코더에 모델 자체의 예측 출력 대신 실제 출력("je suis etudiant")이 제공됩니다.
  Seq2Seq 모델 (계속)
  
  인코더의 은닉 상태를 𝒉𝟏, 𝒉𝟐, ... 𝒉𝑵으로 표시합니다.
  인코더로부터의 컨텍스트 벡터를 𝒂로 표시합니다.
  따라서 𝒂=𝒉𝑵, 즉 아래 구조에서 𝑎=ℎ4와 같습니다.
  마지막 은닉 상태 𝒉𝑁은 입력 시퀀스 전체를 요약합니다.
  디코더의 은닉 상태를 𝒔𝟏, 𝒔𝟐, ... 𝒔𝑻로 표시합니다.

# Seq2Seq 모델의 한계점과 해결책
  - 컨텍스트 병목 현상(Context Bottleneck)
  - 정보 손실

  * 디코더의 각 시간 단계마다 컨텍스트 벡터를 생성
  * 인코더의 모든 은닉 상태를 포함하여 컨텍스트 벡터를 생성

# Attention 메커니즘
  - 위 두가지 문제점을 해결하고자 제안
  - 각 디코딩 단계에서 입력 시퀀스의 모든 부분에 대해 가중치를 조정함으로써 중요한 정보에 더 많은 주의를 기울이고, 덜 중요한 정보는 덜 고려하는 방식으로 작동

  * 가중치 a 결정 방법
   - α_i는 현재 디코딩 단계에서 은닉 상태 h_i의 중요도를 나타내야 함
   - h_i의 중요도는 현재 디코딩 단계의 입력 s_t와의 유사성으로부터 얻을 수 있음
   - ∑_i α_i는 1이 되어야 하며, 이는 소프트맥스(softmax) 함수를 사용함으로써 달성


  4가지 단계를 다음과 같이 진행
  1. 어텐션 스코어를 구한다.
  2. 소프트맥스(softmax) 함수를 통해 어텐션 분포(Attention Distribution)를 구한다.
  3. 각 인코더의 어텐션 가중치와 은닉 상태를 가중합하여 어텐션 값(Attention Value)을 구한다.
  4. 어텐션 값과 디코더의 t 시점의 은닉 상태를 연결한다. (concat)
  5. 출력층 연산의 입력이 되는 s_tilda를 계산합니다.

  ## 다양한 종류의 score
    - doc-prod
    - scaled dot-product
    - Bilinear
    - Multi-layer (General)
