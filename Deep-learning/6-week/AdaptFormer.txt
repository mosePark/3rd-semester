# 요약
  ## 문제점
    - 각각의 이미지 및 비디오 인식 작업에 적응하기 위해 ViTs를 파인튜닝하는 과정이 막대한 계산, 메모리를 요구하며, 이는 다양한 시각 도메인으로의 전이성을 제한함
  ## 해결책
    -AdaptFormer는 pre-train된 ViTs에 2% 미만의 추가 파라미터만을 더하는 경량 모듈을 도입하여, 원래의 파라미터를 업데이트하지 않고도 다양한 작업에 적응할 수 있게 함으로써 ViTs의 전이성을 크게 향상시키는 방법 제안

# 제안하는 방법론
  ## 접근 방식
    - ViT에 단 2%의 추가 파라미터를 덧붙인 경량화 방식
    - original ViT의 사전 학습 파라미터들을 조정할 필요 없음
      → ViT의 transferability를 향상
    - action recognition task에서 기존 fine tuning model들보다 우수한 결과를 낳음

# 궁금한 점
  - attention 메커니즘에 대한 이해가 필요 → 기계학습 수업 때 들었지만 아직 재대로된 이해가 필요하다고 판단.
    - 도움이 되는 영상 : [attention 시각화 영상](https://www.youtube.com/watch?v=eMlx5fFNoYc)

# 느낀 점
  - 논문 읽기의 회차를 거듭할수록 딥러닝 지식이 많이 부족하다는 것을 느꼈습니다.
